{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0cf2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 shuffle\n",
    "# import random\n",
    "# with open('./train_hate_dataset_v1.txt', 'r', encoding='utf-8') as f:\n",
    "#     file = f.read()\n",
    "# files = file.split('\\n')\n",
    "# with open('./test_hate_dataset_v1.txt', 'r', encoding='utf-8') as f:\n",
    "#     file2 = f.read()\n",
    "# files2 = file2.split('\\n')\n",
    "# files.extend(files2)\n",
    "# random.shuffle(files)\n",
    "# sentences = [x.split('\\t') for x in files]\n",
    "# len_sentences = len(sentences)\n",
    "# splited_len = round(len_sentences*0.9)\n",
    "# train_sentences = sentences[:splited_len]\n",
    "# test_sentences = sentences[splited_len:]\n",
    "# train_sentences = pd.DataFrame(train_sentences)\n",
    "# test_sentences = pd.DataFrame(test_sentences)\n",
    "# train_sentences.to_csv('./train_hate_dataset_v2.txt', sep='\\t', index=None, header=None)\n",
    "# test_sentences.to_csv('./test_hate_dataset_v2.txt', sep='\\t', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7140b5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import jamotools #자모 단위 토큰화\n",
    "import re\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from gluonnlp.data import SentencepieceTokenizer\n",
    "from kobert.utils import get_tokenizer\n",
    "\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, mode):\n",
    "        self.sentences = [line[sent_idx] for line in dataset]\n",
    "        self.labels = [int(line[label_idx]) for line in dataset]\n",
    "        self.korean = re.compile('[^1!ㄱ-ㅣ가-힣]+')\n",
    "        self.mode = mode\n",
    "        tok_path = '.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece'\n",
    "        self.sp = SentencepieceTokenizer(tok_path)\n",
    "        self.vocab = self.make_vocab()\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.q3 = self.get_q3()\n",
    "        self.char2idx = {u:i for i, u in enumerate(self.vocab)}\n",
    "        self.idx2char = {i:u for i, u in enumerate(self.vocab)}\n",
    "        self.max_len = self.find_max_len()\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return (self.preprocess_sentence(self.sentences[i]), torch.tensor(self.labels[i]).to(torch.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def make_vocab(self):\n",
    "        vocab = ''\n",
    "        for sentence in self.sentences:\n",
    "            vocab+=' '+sentence\n",
    "        vocab = self.make_token(vocab)\n",
    "        vocab = set(vocab)\n",
    "        vocab = sorted(vocab)\n",
    "        vocab.append('<UNK>') #######\n",
    "        vocab.append('<PAD>')\n",
    "        return vocab\n",
    "    \n",
    "    def make_token(self, sentence):\n",
    "        if self.mode == 'jamo':\n",
    "            chars = self.korean.sub('', jamotools.split_syllables(sentence))\n",
    "            return list(chars)\n",
    "        elif self.mode == 'char':\n",
    "            chars = self.korean.sub('', sentence)\n",
    "            return list(chars)\n",
    "        elif self.mode == 'sentencepiece':\n",
    "            return self.sp(sentence)\n",
    "        \n",
    "    def preprocess_sentence(self, sentence):\n",
    "        chars = self.make_token(sentence)\n",
    "        if len(chars) < self.q3:\n",
    "            need_pad = self.q3 - len(chars)\n",
    "            chars.extend(['<PAD>']*need_pad)\n",
    "        else:\n",
    "            chars = chars[:self.q3]\n",
    "        chars = torch.tensor([self.char2idx[x] for x in chars]).to(torch.int64)\n",
    "        return chars\n",
    "    \n",
    "    def find_max_len(self):\n",
    "        return max(len(self.make_token(item)) for item in self.sentences)\n",
    "    \n",
    "    def find_max_idx(self):\n",
    "        return self.sentences[np.argmax([len(self.make_token(item)) for item in self.sentences])]\n",
    "\n",
    "    \n",
    "    def get_q3(self):\n",
    "        values = np.array([len(self.make_token(x)) for x in self.sentences])\n",
    "        return int(np.quantile(values, 1.0))\n",
    "    \n",
    "    \n",
    "    def plot_len(self):\n",
    "        values = np.array([len(self.make_token(x)) for x in self.sentences])\n",
    "        plt.hist(values, density=True, bins=80)\n",
    "        plt.ylabel('count')\n",
    "        plt.xlabel('length of sequence')\n",
    "        plt.show()\n",
    "        print('문장 최대 길이 :',self.max_len)\n",
    "        results = stats.describe(values)\n",
    "        print('min={}, max={}, mean={}, Q2={} Q3={}'.format(results[1][0], results[1][1], results[2],\n",
    "                                                          np.median(values), np.quantile(values, 0.75)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd27259",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, filters, embedding_dim, num_of_kernel):\n",
    "        super().__init__()\n",
    "        self.filters=filters\n",
    "        self.dropout_prob = 0.5\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_of_kernel = num_of_kernel\n",
    "        self.embedding = nn.Embedding(vocab_size, self.embedding_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(self.num_of_kernel)\n",
    "        for i in range(len(self.filters)):\n",
    "            conv = nn.Conv1d(in_channels=self.embedding_dim, out_channels=self.num_of_kernel, kernel_size=self.filters[i])\n",
    "            setattr(self, f'conv_{i}', conv)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=self.dropout_prob)\n",
    "        self.bn2 = nn.BatchNorm1d(self.num_of_kernel*len(self.filters))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.num_of_kernel*len(self.filters), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def get_conv(self, i):\n",
    "        return getattr(self, f'conv_{i}')\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        x = self.embedding(inp)\n",
    "        x = x.permute(0, 2, 1) ### embedding 을 transpose해줘야함.안하면 1d-conv이 seq 방향이 아닌, 임베딩 방향으로 진행됨.\n",
    "        conv_results = [\n",
    "            F.relu(self.bn1(self.get_conv(i)(x))).permute(0,2,1).max(1)[0]\n",
    "        for i in range(len(self.filters))]\n",
    "        x = torch.cat(conv_results, 1)\n",
    "        x = self.classifier(x)\n",
    "        x = x.squeeze()\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b329fd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "mode : char\n",
      "lr : 4e-05\n",
      "embedding_dim : 1000\n",
      "filters : [4, 5, 6]\n",
      "num_of_kernel : 100\n",
      "================\n",
      "epoch 1 train accuracy 0.722 f1_score 0.520 precision 0.669 recall 0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 test accuracy 0.631 f1_score 0.000 precision 0.000 recall 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13604\\2271823303.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                             \u001b[1;31m#print('losses :', loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 110\n",
    "learning_rates = [4e-5]\n",
    "filters = [[4,5,6]]\n",
    "embedding_dim = [1000]\n",
    "num_of_kernel = [100]\n",
    "mode = ['char'] # jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\n",
    "\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset('./data/train_hate_dataset_v2.txt')\n",
    "dataset_test = nlp.data.TSVDataset('./data/test_hate_dataset_v2.txt')\n",
    "\n",
    "best_f1 = 0\n",
    "for mode0 in mode:\n",
    "    for learning_rate in learning_rates:\n",
    "        for embedding_dim0 in embedding_dim:\n",
    "            for filters0 in filters:\n",
    "                for num_of_kernel0 in num_of_kernel:\n",
    "                    \n",
    "                    print('================')\n",
    "                    print('mode : {}'.format(mode0))\n",
    "                    print('lr : {}'.format(learning_rate))\n",
    "                    print('embedding_dim : {}'.format(embedding_dim0))\n",
    "                    print('filters : {}'.format(filters0))\n",
    "                    print('num_of_kernel : {}'.format(num_of_kernel0))\n",
    "                    print('================')\n",
    "                    \n",
    "                    data_train = CharDataset(dataset_train, 0, 1, mode=mode0)\n",
    "                    data_test = CharDataset(dataset_test, 0, 1, mode=mode0)\n",
    "\n",
    "                    train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, drop_last=True)\n",
    "                    test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "                    model = Net(data_train.vocab_size, data_train.get_q3(), filters0, embedding_dim0, num_of_kernel0)\n",
    "                    model.to(device)\n",
    "                    criterion = nn.BCELoss()\n",
    "                    #criterion = nn.CrossEntropyLoss()\n",
    "                    #optimizer = optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "                    #optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "                    #optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "                    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.1)\n",
    "\n",
    "#                     scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "#                                                     lr_lambda=lambda epoch: 0.95 ** epoch,\n",
    "#                                                     last_epoch=-1,\n",
    "#                                                     verbose=False)\n",
    "\n",
    "                    for epoch in range(epochs):\n",
    "\n",
    "                        running_loss = 0.0\n",
    "                        correct = 0\n",
    "                        y_true, y_pred = [], []\n",
    "                        model.train()\n",
    "                        for i, data in enumerate(train_dataloader, 0):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device)\n",
    "                            labels = labels.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            #print('losses :', loss)\n",
    "                            running_loss = loss.item()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            #scheduler.step()\n",
    "                            pred = (outputs>0.5).to(torch.float)\n",
    "                            y_pred.extend(pred)\n",
    "                            y_true.extend(labels)\n",
    "                        y_true_cpu = [int(x) for x in y_true]\n",
    "                        y_pred_cpu = [int(x) for x in y_pred]\n",
    "                        correct = sum([(x==y) for x,y in zip(y_pred, y_true)])\n",
    "                        precision = precision_score(y_true_cpu, y_pred_cpu)\n",
    "                        recall = recall_score(y_true_cpu, y_pred_cpu)\n",
    "                        f1= f1_score(y_true_cpu, y_pred_cpu)\n",
    "                        print(\"epoch {} train accuracy {:.3f} f1_score {:.3f} precision {:.3f} recall {:.3f}\".format(epoch+1, correct / (len(y_pred)), f1, precision, recall))\n",
    "\n",
    "                        model.eval()\n",
    "                        y_true, y_pred = [], []\n",
    "                        running_loss = 0.0\n",
    "                        correct = 0\n",
    "                        for i, data in enumerate(test_dataloader, 0):\n",
    "                            inputs, labels = data\n",
    "                            inputs = inputs.to(device)\n",
    "                            labels = labels.to(device)\n",
    "                            outputs = model(inputs)\n",
    "                            pred = (outputs>0.5).to(torch.float)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            running_loss += loss.item()\n",
    "                            y_pred.extend(pred)\n",
    "                            y_true.extend(labels)\n",
    "                        y_true_cpu = [x.cpu() for x in y_true]\n",
    "                        y_pred_cpu = [x.cpu() for x in y_pred]\n",
    "                        correct = sum([(x==y) for x,y in zip(y_pred, y_true)])\n",
    "                        precision = precision_score(y_true_cpu, y_pred_cpu)\n",
    "                        recall = recall_score(y_true_cpu, y_pred_cpu)\n",
    "                        f1 = f1_score(y_true_cpu, y_pred_cpu)\n",
    "                        print(\"epoch {} test accuracy {:.3f} f1_score {:.3f} precision {:.3f} recall {:.3f}\".format(epoch+1, correct / (len(y_pred)), f1, precision, recall))\n",
    "                        if epoch == 10 and f1 < 0.3:\n",
    "                            break\n",
    "                            \n",
    "                        if f1 > best_f1:\n",
    "                            best_model = model\n",
    "                            best_f1 = f1\n",
    "                    print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6475333",
   "metadata": {},
   "source": [
    "## save 1dcnn_sentencepiece.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d4f4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7268\\1361514895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./check_point/1dcnn_sentencepiece.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(best_model.state_dict(), './check_point/1dcnn_sentencepiece.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92242013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360824742268041"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1483eb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18976\\1304129891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_q3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./check_point/1dcnn_sentencepiece.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    710\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    713\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[1;34m(saved_id)\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumel\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_element_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m             \u001b[0mload_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[1;34m(dtype, numel, key, location)\u001b[0m\n\u001b[0;32m    999\u001b[0m         \u001b[1;31m# stop wrapping with _TypedStorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m         loaded_storages[key] = torch.storage._TypedStorage(\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mwrap_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrestore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m             dtype=dtype)\n\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[1;34m(storage, location)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[1;34m(obj, location)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mstorage_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[1;34m(self, device, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model = Net(data_train.vocab_size, data_train.get_q3(), [4,5,6], 1000, 100)\n",
    "model.load_state_dict(torch.load('./check_point/1dcnn_sentencepiece.pt'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1d40d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18976\\2291661927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sentencepiece'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mcb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "prefix = './'\n",
    "epochs = 30\n",
    "batch_size = 110\n",
    "learning_rates = [4e-5]\n",
    "filters = [[4,5,6]]\n",
    "embedding_dim = [1000]\n",
    "num_of_kernel = [100]\n",
    "mode = ['sentencepiece'] # jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\n",
    "\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset('./data/train_hate_dataset_v2.txt')\n",
    "dataset_test = nlp.data.TSVDataset('./data/test_hate_dataset_v2.txt')\n",
    "                                   \n",
    "data_train = CharDataset(dataset_train, 0, 1, mode=mode[0])\n",
    "data_test = CharDataset(dataset_test, 0, 1, mode=mode[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec630da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 443,  360,   41, 4763, 4205, 5250, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402, 6402,\n",
      "        6402, 6402, 6402])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18976\\1056583839.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar2idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mchars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mprt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "sentence = 'ㅆ1발놈아'\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    korean = re.compile('[^1!ㄱ-ㅣ가-힣]+')\n",
    "    chars = korean.sub('', sentence)\n",
    "    chars = data_train.make_token(chars)\n",
    "    if len(chars) < data_train.get_q3():\n",
    "        need_pad = data_train.get_q3() - len(chars)\n",
    "        chars.extend(['<PAD>']*need_pad)\n",
    "    else:\n",
    "        chars = chars[:data_train.q3]\n",
    "    chars = torch.tensor([data_train.char2idx[x] for x in chars]).to(torch.int64)\n",
    "    print(chars)\n",
    "    chars = chars.to(device)\n",
    "    chars = torch.unsqueeze(chars, 0)\n",
    "    prt = [data_train.idx2char[x.item()] for x in chars.squeeze()]\n",
    "    print(prt)\n",
    "    print(chars)\n",
    "    outputs = model(chars)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2bf86c",
   "metadata": {},
   "source": [
    "## save 1dcnn_jamo.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77689219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(1668, 1000)\n",
       "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_0): Conv1d(1000, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_1): Conv1d(1000, 100, kernel_size=(5,), stride=(1,))\n",
       "  (conv_2): Conv1d(1000, 100, kernel_size=(6,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4cb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5360824742268041"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2020c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18976\\2566445387.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./check_point/1dcnn_jamo.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# .cpu() on the underlying Storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m         \u001b[1;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\storage.py\u001b[0m in \u001b[0;36mcpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;34m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_type\u001b[1;34m(self, dtype, non_blocking, **kwargs)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.save(best_model.state_dict(), './check_point/1dcnn_jamo.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6568534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "prefix = './'\n",
    "epochs = 30\n",
    "batch_size = 110\n",
    "learning_rates = [4e-5]\n",
    "filters = [[4,5,6]]\n",
    "embedding_dim = [1000]\n",
    "num_of_kernel = [100]\n",
    "mode = ['jamo'] # jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\n",
    "\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset('./data/train_hate_dataset_v2.txt')\n",
    "dataset_test = nlp.data.TSVDataset('./data/test_hate_dataset_v2.txt')\n",
    "                                   \n",
    "data_train = CharDataset(dataset_train, 0, 1, mode='jamo')\n",
    "data_test = CharDataset(dataset_test, 0, 1, mode='jamo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb33a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(54, 1000)\n",
       "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_0): Conv1d(1000, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_1): Conv1d(1000, 100, kernel_size=(5,), stride=(1,))\n",
       "  (conv_2): Conv1d(1000, 100, kernel_size=(6,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(data_train.vocab_size, data_train.get_q3(), [4,5,6], 1000, 100)\n",
    "model.load_state_dict(torch.load('./check_point/1dcnn_jamo.pt'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c247b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 37, 23, 21, 51,  5, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "        53, 53, 53, 53, 53, 53, 53, 53, 53])\n",
      "['ㅂ', 'ㅕ', 'ㅇ', 'ㅅ', 'ㅣ', 'ㄴ', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "tensor([[18, 37, 23, 21, 51,  5, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "         53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53,\n",
      "         53, 53, 53, 53, 53, 53, 53, 53, 53]], device='cuda:0')\n",
      "tensor(0.5163, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sentence = ''\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    korean = re.compile('[^1!ㄱ-ㅣ가-힣]+')\n",
    "    chars = korean.sub('', sentence)\n",
    "    chars = data_train.make_token(chars)\n",
    "    if len(chars) < data_train.get_q3():\n",
    "        need_pad = data_train.get_q3() - len(chars)\n",
    "        chars.extend(['<PAD>']*need_pad)\n",
    "    else:\n",
    "        chars = chars[:data_train.q3]\n",
    "    chars = torch.tensor([data_train.char2idx[x] for x in chars]).to(torch.int64)\n",
    "    print(chars)\n",
    "    chars = chars.to(device)\n",
    "    chars = torch.unsqueeze(chars, 0)\n",
    "    prt = [data_train.idx2char[x.item()] for x in chars.squeeze()]\n",
    "    print(prt)\n",
    "    print(chars)\n",
    "    outputs = model(chars)\n",
    "    print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2113b",
   "metadata": {},
   "source": [
    "## save 1dcnn_char.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bbd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(1668, 1000)\n",
       "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_0): Conv1d(1000, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_1): Conv1d(1000, 100, kernel_size=(5,), stride=(1,))\n",
       "  (conv_2): Conv1d(1000, 100, kernel_size=(6,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6d400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5409356725146198"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bc189",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), './check_point/1dcnn_char.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704002f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18116\\742354455.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'char'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\random.py\u001b[0m in \u001b[0;36mmanual_seed\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_in_bad_fork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mmanual_seed_all\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m         \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;31m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Safwan\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\torch\\cuda\\random.py\u001b[0m in \u001b[0;36mcb\u001b[1;34m()\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[0mdefault_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_generators\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0mdefault_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[0m_lazy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed_all\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "prefix = './'\n",
    "epochs = 30\n",
    "batch_size = 110\n",
    "learning_rates = [4e-5]\n",
    "filters = [[4,5,6]]\n",
    "embedding_dim = [1000]\n",
    "num_of_kernel = [100]\n",
    "mode = ['char'] # jamo : 자음,모음 단위로 토큰화. char : 한글자 단위로 토큰화\n",
    "\n",
    "torch.manual_seed(21)\n",
    "np.random.seed(21)\n",
    "random.seed(21)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "dataset_train = nlp.data.TSVDataset('./data/train_hate_dataset_v2.txt')\n",
    "dataset_test = nlp.data.TSVDataset('./data/test_hate_dataset_v2.txt')\n",
    "                                   \n",
    "data_train = CharDataset(dataset_train, 0, 1, mode='char')\n",
    "data_test = CharDataset(dataset_test, 0, 1, mode='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6f864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (embedding): Embedding(1668, 1000)\n",
       "  (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_0): Conv1d(1000, 100, kernel_size=(4,), stride=(1,))\n",
       "  (conv_1): Conv1d(1000, 100, kernel_size=(5,), stride=(1,))\n",
       "  (conv_2): Conv1d(1000, 100, kernel_size=(6,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (bn2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(data_train.vocab_size, data_train.get_q3(), [4,5,6], 1000, 100)\n",
    "model.load_state_dict(torch.load('./check_point/1dcnn_char.pt'))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1446592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 387, 1223,   46, 1106,  291,   17,   17, 1667, 1667, 1667, 1667, 1667,\n",
      "        1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667,\n",
      "        1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667])\n",
      "['돼', '지', '같', '은', '놈', 'ㅋ', 'ㅋ', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "tensor([[ 387, 1223,   46, 1106,  291,   17,   17, 1667, 1667, 1667, 1667, 1667,\n",
      "         1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667,\n",
      "         1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667, 1667]],\n",
      "       device='cuda:0')\n",
      "tensor(0.5369, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model = best_model\n",
    "sentence = '돼지같은놈 ㅋㅋ'\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    korean = re.compile('[^1!ㄱ-ㅣ가-힣]+')\n",
    "    chars = korean.sub('', sentence)\n",
    "    chars = data_train.make_token(chars)\n",
    "    if len(chars) < data_train.get_q3():\n",
    "        need_pad = data_train.get_q3() - len(chars)\n",
    "        chars.extend(['<PAD>']*need_pad)\n",
    "    else:\n",
    "        chars = chars[:data_train.q3]\n",
    "    chars = torch.tensor([data_train.char2idx[x] for x in chars]).to(torch.int64)\n",
    "    print(chars)\n",
    "    chars = chars.to(device)\n",
    "    chars = torch.unsqueeze(chars, 0)\n",
    "    prt = [data_train.idx2char[x.item()] for x in chars.squeeze()]\n",
    "    print(prt)\n",
    "    print(chars)\n",
    "    outputs = model(chars)\n",
    "    print(outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8f2d011d9b420cfd2a4f7e08465ea0cee8fd2bc9898c96caed1ba79c043953c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
